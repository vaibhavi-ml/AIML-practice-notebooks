# -*- coding: utf-8 -*-
"""Transform, Winsorize, Remove.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q6AYiHwpzQIVxpA9qbVR7kePKHMb6LJk
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
from sklearn.preprocessing import PowerTransformer

"""Preparation of Data"""

np.random.seed(42) #Same random numbers every run â†’ useful when demonstrating code

normal_data=np.random.normal(50, 10, 1000) #Generates 1000 data points. Follows a normal distribution. Mean = 50, Standard deviation = 10. Basically a bell-curve of values centered at 50.

normal_data

outliers=np.array([150,200, -20])

data=np.concatenate([normal_data, outliers])

df=pd.DataFrame({'value': data})

df.head()

df.describe()

"""Detection of Outliers"""

#####Z-Score Method#######
df['z-score']=stats.zscore(df['value'])

outliers_by_zscore=df[df['z-score'].abs()>3]

outliers_by_zscore

"""IQR Method"""

Q1=df['value'].quantile(0.25)

Q3=df['value'].quantile(0.75)

IQR=Q3-Q1



Boxplot_lower_whisker=Q1-1.5*IQR
Boxplot_upper_whisker=Q3+1.5*IQR

outliers_IQR=df[(df['value']<Boxplot_lower_whisker) | (df['value']>Boxplot_upper_whisker)]

outliers_IQR

"""Compare the Two Methods
Z-score Outliers

Only these rows:

209 (â‰ˆ88.5)

1000 (150)

1001 (200)

1002 (-20)

These are extreme â€” many standard deviations away.
Z-score is clearly catching only the most insane values.

Because mean and std dev are heavily influenced by outliers:

The boundary threshold shifts outward

Mild outliers get hidden

IQR Outliers

Much bigger list:
Values around 17â€“24 and 76â€“88 also appear as outliers.

Why?

Because:

ðŸ”¥ IQR method detects values outside the central 50%
and it does NOT care about:

mean

standard deviation

So it catches more subtle data points that are unusual but not extreme.

ðŸ“Œ Interpretation
Method	What it catches	What it misses
Z-score	Extreme points only	Moderate but weird data
IQR	Both extreme + mild odd values	Sometimes too strict on normal tails

This difference tells us a lot:

ðŸ§  What does this tell us about your dataset?

âœ” The distribution is not perfectly normal
âœ” It has a longer right/left tail (skew)
âœ” Outliers affect mean and std strongly
âœ” Z-score is not reliable here (because skew breaks its assumptions)

Result?
â†’ IQR is currently a better tool than z-score

Removing  Outliers
"""

df_removed=df[(df['value']<=Boxplot_upper_whisker) & (df['value']>=Boxplot_lower_whisker)]

df_removed

df_removed.shape

"""Winsorizing Outliers"""

lower_clip=Boxplot_lower_whisker
upper_clip=Boxplot_upper_whisker
#or we can do
#lower_clip=df['value'].quantile(0.01)
#upper_clip=df['value'].quantile(0.99)

df_winsor=df.copy()
df_winsor['value']=df['value'].clip(lower_clip, upper_clip)

df_winsor

df_winsor['value'].describe()

"""Transformation

Winsorizing fixed the extremes
But the distribution likely still has skew.

The next professional step is:

ðŸ‘‰ Apply transformation
(Likely Yeo-Johnson using PowerTransformer)

This will:

Normalize skew

Stabilize variance

Make relationships linear â†’ essential for regression and NN

LOG TRANSFORM
"""

df['log_value']=np.log(df['value']-df['value'].min()+1)

"""SQUAREROOT TRANSFORM"""

df['sqrt_value']=np.sqrt(df['value']-df['value'].min()+1)

"""BOX-COX TRANSFORM (works only when values>0)"""

positive_data=df['value']-df['value'].min()+1
df['boxcox'], lam=stats.boxcox(positive_data)

df.head()

"""YEO-JONHSON TRANSFORM"""

pt=PowerTransformer(method='yeo-johnson')
df['yeo_johnson_value'] = pt.fit_transform(df[['value']])  #used double[[]] because we have to pass a dataframe , not a pandas series to the fit_transform function

df.head()

